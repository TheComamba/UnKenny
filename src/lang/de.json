{
    "unkenny.confirmation.title": "Bestätigung",
    "unkenny.confirmation.question": "Bist du sicher?",
    "unkenny.confirmation.yes": "Ja",
    "unkenny.confirmation.no": "Nein",
    "unkenny.confirmation.confirmed": "Bestätigt",
    "unkenny.confirmation.cancelled": "Abgebrochen",
    "unkenny.chatLog.clearConversations": "Alle UnKenny-Gespräche löschen",
    "unkenny.chatLog.clearConversationsConfirmation": "Bist du sicher, dass du alle UnKenny-Gespräche löschen möchtest? Dies löscht keine Nachrichten.",
    "unkenny.chatLog.removeFromConversation": "Aus UnKenny-Gespräch entfernen",
    "unkenny.chatMessage.actorIdNotFound": "Akteur mit ID \"{id}\" nicht gefunden. Wurde er gelöscht?",
    "unkenny.chatMessage.actorAliasNotFound": "Akteur mit Alias \"{alias}\" nicht gefunden.",
    "unkenny.chatMessage.marker": "Spricht mit {audience}",
    "unkenny.chatMessage.multipleActors": "Mehrere Akteure mit Alias \"{alias}\" gefunden: {names}",
    "unkenny.chatMessage.triggerWithoutActor": "triggerResponse wurde ohne Akteur aufgerufen.",
    "unkenny.chatMessage.noResponse": "Es wurde keine Antwort generiert.",
    "unkenny.chatMessage.jsonParseError": "Fehler beim Verarbeiten von JSON: {error}",
    "unkenny.chatMessage.preambleTooLong": "Das Gespräch hat gerade erst begonnen, ist aber bereits zu lang für das Modell. Dies liegt wahrscheinlich daran, dass die Präambel zu lang ist. Bitte kürze die Präambel oder wechsle zu einem anderen Modell mit einer größeren Kontextlänge.",
    "unkenny.chatMessage.truncatingMessage": "Dieses Gespräch, welches {messageCount} Nachrichten umfasst, ist zu lang für das Modell und wird gekürzt. Um dies in Zukunft zu verhindern, kannst du entweder das Modell wechseln oder das Gespräch verkürzen, indem du vorherige Nachrichten aus dem Gespräch entfernts.",
    "unkenny.chatMessage.noPreamble": "Für Akteur {name} wurde keine Präambel hinterlegt.",
    "unkenny.info.title": "Einen Moment bitte",
    "unkenny.info.message": "Dies kann eine Weile dauern, während der FoundryVTT nicht reagiert.",
    "unkenny.llm.noValue": "Kein Wert für {parameterName} gefunden. Verwende Standardwert {value}.",
    "unkenny.llm.noDefaultValue": "Kein Standardwert für {parameterName} gefunden.",
    "unkenny.llm.openAiError": "Antwort von OpenAI konnte nicht abgerufen werden: {error}",
    "unkenny.prefix.invalid": "Das Präfix \"{prefix}\" wird nicht erkannt und daher ignoriert.",
    "unkenny.settings.model": "Großes Sprachmodell",
    "unkenny.settings.modelDescription": "Das Standardmodell, welches von UnKenny-Akteuren verwendet wird, um Antworten zu generieren.\nLokale Modelle laufen in deinem Browser oder der FoundryVTT-Instanz, während OpenAI-Modelle auf einem anderen Server laufen.\nOpenAI-Modelle sind viel schneller und liefern meist bessere Ergebnisse, erfordern jedoch einen API-Schlüssel, um zu funktionieren.",
    "unkenny.settings.baseUrl": "OpenAI Basis-URL",
    "unkenny.settings.baseUrlDescription": "Die Basis-URL für die OpenAI API. Diese wird nur für OpenAI-Modelle verwendet.",
    "unkenny.settings.openaiApiKey": "OpenAI API-Schlüssel",
    "unkenny.settings.openaiApiKeyDescription": "Falls du OpenAI-Modelle verwenden möchtest, musst du hier deinen API-Schlüssel angeben.\nZusätzlich muss dein Konto ein positives Guthaben haben.",
    "unkenny.settings.minNewTokens": "Minimale Anzahl neuer Token",
    "unkenny.settings.minNewTokensDescription": "In großen Sprachmodellen bestimmt die Anzahl der Token die Länge des generierten Textes.\nUm sehr kurze Antworten zu vermeiden, kannst du hier eine minimale Anzahl von Token festlegen. Hinweis: Dieser Parameter wird nur bei lokalen Modellen berücksichtigt.",
    "unkenny.settings.maxNewTokens": "Maximale Anzahl neuer Token",
    "unkenny.settings.maxNewTokensDescription": "Um übermäßig lange Antworten zu vermeiden, kannst du hier eine maximale Anzahl von Token festlegen.",
    "unkenny.settings.repetitionPenalty": "Wiederholungsstrafe / Häufigkeitsstrafe",
    "unkenny.settings.repetitionPenaltyDescription": "Die Wiederholungsstrafe ist eine Zahl, welche die Wahrscheinlichkeit anpasst, dass ein Token, welches bereits generiert wurde, erneut generiert wird.\nHöhere Werte verringern die Wahrscheinlichkeit von Wiederholungen, negative Werte erhöhen sie.",
    "unkenny.settings.temperature": "Temperatur",
    "unkenny.settings.temperatureDescription": "Große Sprachmodelle generieren Text, indem sie aus einer Wahrscheinlichkeitsverteilung über den Wortschatz auswählen.\nDie Temperatur beeinflusst diese Verteilung:\nBei einer Temperatur von 0 wählt das Modell immer das wahrscheinlichste Token, während alle Token für sehr hohe Temperaturen fast gleich wahrscheinlich werden.\nNiedrigere Werte machen das Modell konservativer, höhere Werte machen es kreativer.",
    "unkenny.settings.prefix": "Stelle Antworten Folgendes voran",
    "unkenny.settings.prefixDescription": "Die Wahl eines nicht-leeren Wertes stellt diesen der generierten Antwort voran. Der <user> Platzhalter wird durch den Namen des aufrufenden Benutzers ersetzt. Das /talk-Makro wird vom Talking Actors FoundryVTT-Modul erkannt.",
    "unkenny.shared.unkenninessForNull": "UnKenniness für null Akteur überprüft.",
    "unkenny.shared.moduleLoadFailed": "Modul \"{name}\" konnte nicht geladen werden: {error}",
    "unkenny.sheet.title": "Bearbeite UnKenniness-Parameter",
    "unkenny.sheet.alias": "Alias",
    "unkenny.sheet.preamble": "Präambel",
    "unkenny.sheet.overwrite": "Globale Parameter überschreiben",
    "unkenny.sheet.save": "Speichern",
    "unkenny.sheet.settingAliasFailed": "Akteur nicht gefunden, das Alias Setzen ist fehlgeschlagen."
}
{
    "unkenny.confirmation.title": "Bestätigung",
    "unkenny.confirmation.question": "Bist du sicher?",
    "unkenny.confirmation.yes": "Ja",
    "unkenny.confirmation.no": "Nein",
    "unkenny.confirmation.confirmed": "Bestätigt",
    "unkenny.confirmation.cancelled": "Abgebrochen",
    "unkenny.chatLog.clearConversations": "Alle UnKenny-Gespräche löschen",
    "unkenny.chatLog.clearConversationsConfirmation": "Bist du sicher, dass du alle UnKenny-Gespräche löschen möchtest? Dies löscht keine Nachrichten.",
    "unkenny.chatLog.removeFromConversation": "Aus UnKenny-Gespräch entfernen",
    "unkenny.chatMessage.actorIdNotFound": "Akteur mit ID \"{id}\" nicht gefunden. Wurde er gelöscht?",
    "unkenny.chatMessage.actorAliasNotFound": "Akteur mit Alias \"{alias}\" nicht gefunden.",
    "unkenny.chatMessage.marker": "Spricht mit {audience}",
    "unkenny.chatMessage.multipleActors": "Mehrere Akteure mit Alias \"{alias}\" gefunden: {names}",
    "unkenny.chatMessage.triggerWithoutActor": "triggerResponse wurde ohne Akteur aufgerufen.",
    "unkenny.chatMessage.noResponse": "Es wurde keine Antwort generiert.",
    "unkenny.chatMessage.jsonParseError": "Fehler beim Verarbeiten von JSON: {error}",
    "unkenny.chatMessage.preambleTooLong": "Das Gespräch hat gerade erst begonnen, ist aber bereits zu lang für das Modell. Dies liegt wahrscheinlich daran, dass die Präambel zu lang ist. Bitte kürze die Präambel oder wechsle zu einem anderen Modell mit einer größeren Kontextlänge.",
    "unkenny.chatMessage.truncatingMessage": "Dieses Gespräch, welches {messageCount} Nachrichten umfasst, ist zu lang für das Modell und wird gekürzt. Um dies in Zukunft zu verhindern, kannst du entweder das Modell wechseln oder das Gespräch verkürzen, indem du vorherige Nachrichten aus dem Gespräch entfernts.",
    "unkenny.chatMessage.noPreamble": "Für Akteur {name} wurde keine Präambel hinterlegt.",
    "unkenny.info.title": "Einen Moment bitte",
    "unkenny.info.message": "Dies kann eine Weile dauern, während der FoundryVTT nicht reagiert.",
    "unkenny.llm.noValue": "Kein Wert für {parameterName} gefunden. Verwende Standardwert {value}.",
    "unkenny.llm.noDefaultValue": "Kein Standardwert für {parameterName} gefunden.",
    "unkenny.llm.preparingModel": "Modell \"{model}\" wird vorbereitet...",
    "unkenny.llm.preparingTokenizer": "Tokenizer für \"{model}\" wird vorbereitet...",
    "unkenny.llm.generatingResponse": "Antwort von {actorName} wird generiert...",
    "unkenny.llm.localLlmError": "Ein Fehler ist während der Textgenerierung mit dem lokalen LLM aufgetreten: {error}",
    "unkenny.llm.openAiError": "Antwort von OpenAI konnte nicht abgerufen werden: {error}",
    "unkenny.settings.model": "Großes Sprachmodell",
    "unkenny.settings.modelDescription": "Das Standardmodell, welches von UnKenny-Akteuren verwendet wird, um Antworten zu generieren.\nLokale Modelle laufen in deinem Browser oder der FoundryVTT-Instanz, während OpenAI-Modelle auf einem anderen Server laufen.\nOpenAI-Modelle sind viel schneller und liefern meist bessere Ergebnisse, erfordern jedoch einen API-Schlüssel, um zu funktionieren.",
    "unkenny.settings.apiKey": "OpenAI API-Schlüssel",
    "unkenny.settings.apiKeyDescription": "Falls du OpenAI-Modelle verwenden möchtest, musst du hier deinen API-Schlüssel angeben.\nZusätzlich muss dein Konto ein positives Guthaben haben.",
    "unkenny.settings.minNewTokens": "Minimale Anzahl neuer Token",
    "unkenny.settings.minNewTokensDescription": "In großen Sprachmodellen bestimmt die Anzahl der Token die Länge des generierten Textes.\nUm sehr kurze Antworten zu vermeiden, kannst du hier eine minimale Anzahl von Token festlegen. Hinweis: Dieser Parameter wird nur bei lokalen Modellen berücksichtigt.",
    "unkenny.settings.maxNewTokens": "Maximale Anzahl neuer Token",
    "unkenny.settings.maxNewTokensDescription": "Um übermäßig lange Antworten zu vermeiden, kannst du hier eine maximale Anzahl von Token festlegen.",
    "unkenny.settings.repetitionPenalty": "Wiederholungsstrafe / Häufigkeitsstrafe",
    "unkenny.settings.repetitionPenaltyDescription": "Die Wiederholungsstrafe ist eine Zahl, welche die Wahrscheinlichkeit anpasst, dass ein Token, welches bereits generiert wurde, erneut generiert wird.\nHöhere Werte verringern die Wahrscheinlichkeit von Wiederholungen, negative Werte erhöhen sie.",
    "unkenny.settings.temperature": "Temperatur",
    "unkenny.settings.temperatureDescription": "Große Sprachmodelle generieren Text, indem sie aus einer Wahrscheinlichkeitsverteilung über den Wortschatz auswählen.\nDie Temperatur beeinflusst diese Verteilung:\nBei einer Temperatur von 0 wählt das Modell immer das wahrscheinlichste Token, während alle Token für sehr hohe Temperaturen fast gleich wahrscheinlich werden.\nNiedrigere Werte machen das Modell konservativer, höhere Werte machen es kreativer.",
    "unkenny.settings.prefixWithTalk": "Antworten /talk voranstellen",
    "unkenny.settings.prefixWithTalkDescription": "Wenn diese Option angewählt und das Talking Actors FoundryVTT-Modul aktiviert und eingerichtet ist, werden die Antworten des Modells von einer KI-Stimme vorgelesen.",
    "unkenny.shared.unkenninessForNull": "UnKenniness für null Akteur überprüft.",
    "unkenny.shared.moduleLoadFailed": "Modul \"{name}\" konnte nicht geladen werden: {error}",
    "unkenny.sheet.title": "Bearbeite UnKenniness-Parameter",
    "unkenny.sheet.alias": "Alias",
    "unkenny.sheet.preamble": "Präambel",
    "unkenny.sheet.overwrite": "Globale Parameter überschreiben",
    "unkenny.sheet.model": "Modell",
    "unkenny.sheet.minTokens": "Minimale Anzahl generierter Token",
    "unkenny.sheet.maxTokens": "Maximale Anzahl generierter Token",
    "unkenny.sheet.repetitionPenalty": "Wiederholungsstrafe",
    "unkenny.sheet.temperature": "Temperatur",
    "unkenny.sheet.save": "Speichern",
    "unkenny.sheet.settingAliasFailed": "Akteur nicht gefunden, das Alias Setzen ist fehlgeschlagen."
}
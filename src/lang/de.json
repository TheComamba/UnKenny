{
    "unkenny.confirmation.title": "Bestätigung",
    "unkenny.confirmation.question": "Bist du sicher?",
    "unkenny.confirmation.yes": "Ja",
    "unkenny.confirmation.no": "Nein",
    "unkenny.confirmation.confirmed": "Bestätigt",
    "unkenny.confirmation.cancelled": "Abgebrochen",
    "unkenny.chatLog.clearConversations": "Alle UnKenny-Gespräche löschen",
    "unkenny.chatLog.clearConversationsConfirmation": "Bist du sicher, dass du alle UnKenny-Gespräche löschen möchtest? Dies löscht keine Nachrichten.",
    "unkenny.chatLog.removeFromConversation": "Aus UnKenny-Gespräch entfernen",
    "unkenny.chatMessage.actorIdNotFound": "Akteur mit ID \"{id}\" nicht gefunden. Wurde er gelöscht?",
    "unkenny.chatMessage.actorAliasNotFound": "Akteur mit Alias \"{alias}\" nicht gefunden.",
    "unkenny.chatMessage.marker": "Spricht mit {audience}",
    "unkenny.chatMessage.multipleActors": "Mehrere Akteure mit Alias \"{alias}\" gefunden: {names}",
    "unkenny.chatMessage.triggerWithoutActor": "triggerResponse wurde ohne Akteur aufgerufen.",
    "unkenny.chatMessage.noResponse": "Es wurde keine Antwort generiert.",
    "unkenny.chatMessage.jsonParseError": "Fehler beim Verarbeiten von JSON: {error}",
    "unkenny.chatMessage.noPreamble": "Für Akteur {name} wurde keine Präambel hinterlegt.",
    "unkenny.info.title": "Einen Moment bitte",
    "unkenny.info.message": "Dies kann eine Weile dauern, während der FoundryVTT nicht reagiert.",
    "unkenny.llm.noValue": "Kein Wert für {parameterName} gefunden. Verwende Standardwert {value}.",
    "unkenny.llm.noDefaultValue": "Kein Standardwert für {parameterName} gefunden.",
    "unkenny.llm.openAiError": "Antwort von OpenAI konnte nicht abgerufen werden: {error}",
    "unkenny.prefix.invalid": "Das Präfix \"{prefix}\" wird nicht erkannt und daher ignoriert.",
    "unkenny.settings.model": "Großes Sprachmodell",
    "unkenny.settings.modelDescription": "Das Standardmodell, welches von UnKenny-Akteuren verwendet wird, um Antworten zu generieren.\nLokale Modelle laufen in deinem Browser oder der FoundryVTT-Instanz, während OpenAI-Modelle auf einem anderen Server laufen.\nOpenAI-Modelle sind viel schneller und liefern meist bessere Ergebnisse, erfordern jedoch einen API-Schlüssel, um zu funktionieren.",
    "unkenny.settings.baseUrl": "Basis URL für OpenAI API",
    "unkenny.settings.baseUrlDescription": "Hier kann die Basis-URL für die Modelle überschrieben werden, die die OpenAI API verwenden.",
    "unkenny.settings.apiKey": "API-Schlüssel",
    "unkenny.settings.apiKeyDescription": "Vermutlich benötigen die von dir verwendeten Modelle einen API-Schlüssel. Den kannst du hier angeben.\nZusätzlich muss dein Konto möglicherweise ein positives Guthaben haben.",
    "unkenny.settings.minNewTokens": "Minimale Anzahl neuer Token",
    "unkenny.settings.minNewTokensDescription": "In großen Sprachmodellen bestimmt die Anzahl der Token die Länge des generierten Textes.\nUm sehr kurze Antworten zu vermeiden, kannst du hier eine minimale Anzahl von Token festlegen. Hinweis: Dieser Parameter wird nur bei lokalen Modellen berücksichtigt.",
    "unkenny.settings.maxNewTokens": "Maximale Anzahl neuer Token",
    "unkenny.settings.maxNewTokensDescription": "Um übermäßig lange Antworten zu vermeiden, kannst du hier eine maximale Anzahl von Token festlegen.",
    "unkenny.settings.repetitionPenalty": "Wiederholungsstrafe / Häufigkeitsstrafe",
    "unkenny.settings.repetitionPenaltyDescription": "Die Wiederholungsstrafe ist eine Zahl, welche die Wahrscheinlichkeit anpasst, dass ein Token, welches bereits generiert wurde, erneut generiert wird.\nHöhere Werte verringern die Wahrscheinlichkeit von Wiederholungen, negative Werte erhöhen sie. Wird nicht von Google Gemini-Modellen unterstützt.",
    "unkenny.settings.temperature": "Temperatur",
    "unkenny.settings.temperatureDescription": "Große Sprachmodelle generieren Text, indem sie aus einer Wahrscheinlichkeitsverteilung über den Wortschatz auswählen.\nDie Temperatur beeinflusst diese Verteilung:\nBei einer Temperatur von 0 wählt das Modell immer das wahrscheinlichste Token, während alle Token für sehr hohe Temperaturen fast gleich wahrscheinlich werden.\nNiedrigere Werte machen das Modell konservativer, höhere Werte machen es kreativer.",
    "unkenny.settings.prefix": "Stelle Antworten Folgendes voran",
    "unkenny.settings.prefixDescription": "Die Wahl eines nicht-leeren Wertes stellt diesen der generierten Antwort voran. Der <user> Platzhalter wird durch den Namen des aufrufenden Benutzers ersetzt. Das /talk-Makro wird vom Talking Actors FoundryVTT-Modul erkannt.",
    "unkenny.shared.unkenninessForNull": "UnKenniness für null Akteur überprüft.",
    "unkenny.shared.moduleLoadFailed": "Modul \"{name}\" konnte nicht geladen werden: {error}",
    "unkenny.sheet.title": "Bearbeite UnKenniness-Parameter",
    "unkenny.sheet.alias": "Alias",
    "unkenny.sheet.preamble": "Präambel",
    "unkenny.sheet.overwrite": "Globale Parameter überschreiben",
    "unkenny.sheet.save": "Speichern",
    "unkenny.sheet.settingAliasFailed": "Akteur nicht gefunden, das Alias Setzen ist fehlgeschlagen."
}